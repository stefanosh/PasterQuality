==============================================================================================================================
Config: /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12.toml
Output: /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
==============================================================================================================================
/home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12.toml
Creating the output...
Using cached X: /home/stefanos/PasterQuality/src/experiments/revisiting_models/data/tabular_split_0/build_X__quantile__mean__new__indices__12.pickle

>>> Epoch 1 | 0:00:00 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.743
[train] score = -6.587 | rmse = 6.587
[val  ] score = -6.295 | rmse = 6.295
[test ] score = -5.250 | rmse = 5.25
New best epoch!

>>> Epoch 2 | 0:00:00 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.633
[train] score = -6.154 | rmse = 6.154
[val  ] score = -6.050 | rmse = 6.05
[test ] score = -5.084 | rmse = 5.084
New best epoch!

>>> Epoch 3 | 0:00:00 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.555
[train] score = -5.840 | rmse = 5.84
[val  ] score = -5.861 | rmse = 5.861
[test ] score = -4.923 | rmse = 4.923
New best epoch!

>>> Epoch 4 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.542
[train] score = -5.582 | rmse = 5.582
[val  ] score = -5.710 | rmse = 5.71
[test ] score = -4.785 | rmse = 4.785
New best epoch!

>>> Epoch 5 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.564
[train] score = -5.313 | rmse = 5.313
[val  ] score = -5.515 | rmse = 5.515
[test ] score = -4.644 | rmse = 4.644
New best epoch!

>>> Epoch 6 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.438
[train] score = -5.100 | rmse = 5.1
[val  ] score = -5.330 | rmse = 5.33
[test ] score = -4.518 | rmse = 4.518
New best epoch!

>>> Epoch 7 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.539
[train] score = -4.920 | rmse = 4.92
[val  ] score = -5.183 | rmse = 5.183
[test ] score = -4.399 | rmse = 4.399
New best epoch!

>>> Epoch 8 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.427
[train] score = -4.765 | rmse = 4.765
[val  ] score = -5.072 | rmse = 5.072
[test ] score = -4.279 | rmse = 4.279
New best epoch!

>>> Epoch 9 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.408
[train] score = -4.612 | rmse = 4.612
[val  ] score = -4.987 | rmse = 4.987
[test ] score = -4.181 | rmse = 4.181
New best epoch!

>>> Epoch 10 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.374
[train] score = -4.484 | rmse = 4.484
[val  ] score = -4.918 | rmse = 4.918
[test ] score = -4.098 | rmse = 4.098
New best epoch!

>>> Epoch 11 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.334
[train] score = -4.348 | rmse = 4.348
[val  ] score = -4.811 | rmse = 4.811
[test ] score = -4.012 | rmse = 4.012
New best epoch!

>>> Epoch 12 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.333
[train] score = -4.230 | rmse = 4.23
[val  ] score = -4.702 | rmse = 4.702
[test ] score = -3.932 | rmse = 3.932
New best epoch!

>>> Epoch 13 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.306
[train] score = -4.132 | rmse = 4.132
[val  ] score = -4.617 | rmse = 4.617
[test ] score = -3.862 | rmse = 3.862
New best epoch!

>>> Epoch 14 | 0:00:01 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.285
[train] score = -4.032 | rmse = 4.032
[val  ] score = -4.528 | rmse = 4.528
[test ] score = -3.801 | rmse = 3.801
New best epoch!

>>> Epoch 15 | 0:00:02 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.327
[train] score = -3.945 | rmse = 3.945
[val  ] score = -4.481 | rmse = 4.481
[test ] score = -3.749 | rmse = 3.749
New best epoch!

>>> Epoch 16 | 0:00:02 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.263
[train] score = -3.878 | rmse = 3.878
[val  ] score = -4.451 | rmse = 4.451
[test ] score = -3.702 | rmse = 3.702
New best epoch!

>>> Epoch 17 | 0:00:02 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.275
[train] score = -3.784 | rmse = 3.784
[val  ] score = -4.364 | rmse = 4.364
[test ] score = -3.654 | rmse = 3.654
New best epoch!

>>> Epoch 18 | 0:00:02 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.303
[train] score = -3.693 | rmse = 3.693
[val  ] score = -4.276 | rmse = 4.276
[test ] score = -3.599 | rmse = 3.599
New best epoch!

>>> Epoch 19 | 0:00:02 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.265
[train] score = -3.590 | rmse = 3.59
[val  ] score = -4.134 | rmse = 4.134
[test ] score = -3.532 | rmse = 3.532
New best epoch!

>>> Epoch 20 | 0:00:02 | /home/stefanos/PasterQuality/src/experiments/revisiting_models/output_pasterquality/tabular_split_0/dcn2/tuned/12
lr = 1.761831490264707e-05 | batch_size = 32 | epoch_size = 9 | n_parameters = 2395216
[train] loss = 0.278